---
layout: post
title: 使用DNS序列定位APT攻击中受感染的主机
tags: []
categories:
  - paper阅读笔记
author: 1ss4k
date: 2021-03-16 16:49:00
---
## Introduction

1、列出了一些重大的经典的攻击

* Aurora 

参考 https://www.mcafee.com/blogs/other-blogs/mcafee-labs/more-details-on-operation-aurora/

* Stuxnet

震网

2、APTs严重威胁着网络安全，可能会窃取用户的信息，造成损失。他们会把自己伪装成合法用户，逐渐提权，使得自己难以被检测到。现有的主要方法是检测恶意域名。

3、有些方法用web request graphs的方法来进行检测。

4、本文主要贡献如下：

(1)确定了某一**时间段**之内主机请求的DNS序列的特征，并且将他们量化成feature，在用它来定位受威胁的主机。

(2)通过分析DNS日志中的请求序列的时间模式，检测APTs，而这不需要恶意域名。

(3)在真实的大规模网络环境中进行实验，收集了70天的数据进行测试及评估。并且也在公开的数据集上进行了实验。

(4)用现有的恶意域名的方法对公开的数据集进行处理，证明了现有的别人的恶意域名方法的有限性。

## Related work



1、使用域名的方法

[35]使用ELM(extreme learning machine)。

[21]重点关注不平衡的DNS流量。



2、使用web request graph的方法

[18]基于web请求之间的独立性 重建了web请求图，将白名单之外的孤立节点视为可疑域名。

[31]采用belief propagation frameworks (信任传播框架)。 

[13]提出MUSE，可以在企业网络中系统地量化并排名。

这些 方法都是由已的恶意域名得到未知的，但是我们已知的恶意域名较少，并且其变化很快。



3、其他可能有启发的方法

[25]关注内部主机出去的流量，计算主机的得分并排名。

[23]基于DNS流量的相似性，提出了一个规模可变的僵尸组网络的检测方法。

等等等

## Scenario & heuristics



下面主要讨论了APTs的生命周期、本文的动机以及一些设想。

1、APT的几个阶段

​	攻击者可以获得大量的资源、数据，经过精心的准备然后实施攻击，并且他们还会尽可能地去隐藏自己，这使得攻击难以检测。

​	研究通常将APT的生命周期划分为3-7个阶段，如下图：
![upload successful](/images/pasted-264.png)

​	首先进行信息收集、指定攻击计划。这一阶段的攻击行为难以被检测。通常通过钓鱼或水坑攻击，对组织内部员工进行攻击，随后进行渗透，建立自己的footthold。随后提权，进行内部勘查，侧向移动，maintain presence，不断循环这个阶段，最后完成任务。一般攻击者为了隐藏自己，要使用HTTP/HTTPS服务，传输得到的数据。此阶段要用到C&C服务。

​	DNS日志记录着需要进行解析的所有请求，这个过程不是在短时间内完成的，这意味着恶意通信留下的痕迹及其时间模式可以作为有效的检测目标。



2、假设

​	在正式请求之前，恶意软件通常用合法域来测试网络连接。当受感染的主机搜索C&C服务器时，它通常会解码一个或多个字符串，这些字符串通常来自恶意软件自己的二进制文件。有时攻击者也会把与C&C通信相关的命令编码放在个人博客或社交网站上，受感染的主机访问博客内容，执行相关操作。

​	一旦数据过滤开始，流量将显著增加。[38]说明了请求数和时间之间关系，以及流量和时间之间的关系。下图表示某一阶段请求和通信量激增。
![upload successful](/images/pasted-265.png)
​	此外，还有一个有趣的现象，某些看似无关的域名总是出现在一起。这是因为一些APT活动设置多级C&C服务以避免服务器检测。基于如上分析，提出如下假设：

(1)当主机与C&C服务器通信时，请求可能会变得更频繁（无论是针对相同的域还是不同的域），请求的域的数量也会增加。

(2)要查找C&C服务器，可能会在某一天的特定时间或固定时间间隔，对同一域进行每周/每月的固定请求。

(3)在查找C&C服务器或与之通信的过程中，可能会出现固定短时间间隔的频繁请求。

(4)看似无关的域名可能会一起出现。

(5)在连接到C&C服务器之前和之后，受感染的主机可能会请求一些简单的合法域名。

## 本文方案



本文方法的思路主要包括三个部分:

1）预处理

2）提取每个host的特征向量，构造一个多维度的特征空间。

3）利用无监督的方法，在多维空间中对特征进行聚类

​	除了在不同主机之间进行比较，还要考虑某一时间段中同一主机的功能变化，且本文的方法是无监督的。本文将NAT作为一个整体来考虑，暂时忽略了NAT的性能对实验的影响。流程图如下所示：

![upload successful](/images/pasted-266.png)

1、预处理

​	不同的日志系统结构也不同，为了便于移植，仅包含必要的字段，如：内部主机IP地址、请求的域名、访问日期和访问时间。具体的操作步骤如下：

* 将日志转为可解释的文件类型，如ARFF、CSV。

* 删除无用字段。

* 按照主机序列和时间序列排序。

预处理完之后得到的数据格式如下：

![upload successful](/images/pasted-267.png)

2、特征提取

此处使用的所有特征都是基于前文的假设提取的。首先，有以下五个基本特性：

（1） 请求总数。（根据假设1）

Feature1=Count{请求数}

（2） 域名总数。（根据假设1）

Feature2=Count{domains}

（3） 在同一时间间隔内对同一域的请求数。

Feature3=Count{相同T的请求数}

（4） 同一短时间间隔内的频繁请求数。（根据假设3）此处将时间间隔设置为2.5 s。

Feature4=Count{相同δ的请求数}

（5）同时出现不相关域名的次数。（根据假设4）此处“同时”定义为1s

Feature5=Count{在ε出现不相关的域}

​	考虑假设5，在连接到C&C服务器之前或结束通信之后，受感染的主机通常会向大型公共论坛或合法的社区发送请求，以测试网络连接或作为结束通信并使恶意软件休眠的信号。但是本文没有把假设5量化为特征向量，但是，这一假设可以作为今后工作的重要参考。

​	但是上面的5个特征并不都是具有意义的，比如特征3周期不确定。所以仅考虑特征1、2、4。

（6） 请求数的变异系数，表示特征1的变异系数。

（7） 域数的变异系数，表示特征2的变异系数。

（8） 具有相同短间隔的频繁请求数的变异系数，表示特征4的变异系数。

​	变异系数表示主机在同一时间间隔内发送的请求的特征变化(计算公式是：与平均值的最大差值)，反映了随时间变化的规律性。恶意的请求这些值经常发生突变，所以一般值都更大一些。

​	设定时间粒度t为1天。由于APT活动的生命周期很长，太细的粒度会导致偏差和失去通用性。典型的工作/学习时间是一周。因此，时间窗口的总长度不需要超过7d。窗口大小过大将产生有误导性的平均值，窗口大小过小将不会产生显著的结果，最终选择了一个5天。



3、无监督学习

​	可以用标准化欧氏距离来表示空间中点之间的关系。考虑了多种算法，如基于密度的DBSCAN和层次聚类。参数对算法的效果有很大的影响，我们尽量选择很少或没有参数的模型，如k-means聚类。K-means算法的参数较少。在效率方面，K-means算法的时间复杂度和空间复杂度均低于层次聚类等算法。

​	聚类的数目不能主观推测。与传统的聚类算法不同，Canopy算法不需要用户预先指定聚类数目，它的速度较快，但是准确度不高。因此我们可以首先用它生成粗糙聚类，得到合适的k值，然后利用k均值对聚类进行细化。

## 实验结果评估



1、数据搜集

​	实验的原始数据来自真实的大规模校园网环境。获得2018年连续70天的DNS日志系统记录，包括1300317135个请求记录，包括内部主机IP地址、访问域名、源端口号、访问日期、时间和各种其他参数。各个参数的主要属性如下：

![upload successful](/images/pasted-268.png)

​	并且，还从APT技术报告中得到了一些模拟数据(地址 https://pan.baidu.com/s/1MKrsVHKFNQdokkQN-Trf7A#list/path=%2F 提取码：1f0g)，大概有超过70天的263个主机的DNS请求记录和总共600414334个请求。包含的字段同样包括主机IP地址、域名、日期和时间。

![upload successful](/images/pasted-269.png)

​	这里数据规模非常大，预处理之后，将数据降到100GB以下。提取特征后，特征文件只需要15.5 MB的存储空间。

​	各种特征分布的直方图如下，横坐标表示特征值，纵坐标表示host数，并且纵坐标刻度是不均匀的，可以看成值的对数。在如下的8个特征中，特征3分为7个区间，其余特征分为10个区间。

![upload successful](/images/pasted-270.png)

2、实验结果

​	本文使用weka 3.8.1将特征标准化，将所有特征的值归一化到区间[0,1]，并执行Canopy。不断调整参数T1和T2，而簇的数目的结果为10个保持不变。所以确定了后续k-means操作的时候簇的数目为10。

​	计算每个簇的平均特征，如下表所示。

![upload successful](/images/pasted-271.png)

​	由表中数据可知，集群8的特征的值高于其他主机，作者使用它进行后续分析，结果如下表：

![upload successful](/images/pasted-272.png)

​	相应的指标如下：

![upload successful](/images/pasted-273.png)

​	可以看到结果是比较好的。随后作者分析了FP产生的可能的原因，经过分析发现：被误认为受感染主机的主机发出了许多请求，导致相应的特征值很高。检查他们的执行记录，发现他们都执行了大量的爬虫程序。

​	此外，还分别去除掉某个特征，验证其他特征的有效性，结果如下表。其中，横轴表示不存在这个特征。

![upload successful](/images/pasted-274.png)

​	此外，作者还在公开数据集上进行了实验，数据下载地址https://data.4tu.nl/articles/dataset/DNS_Queries_to_Authoritative_DNS_Server_at_SURFnet_by_Google_s_Public_DNS_Resolver/12682040。作者选取了两个月的数据进行实验，包括总共380487036个DNS请求。我们的方法中特征5需要使用到域名，但该数据集对域名进行了哈希运算，所以此处不能再运用特征5，本文使用了除特征5之外的7个特征。随后实验中，聚类数设为3。其他实验步骤和之前所述相同。



3、对比实验

​	对照实验的作者基于静态DNS日志，提取了域名的9个特征。

​	基于梯度，设置了隐藏节点的数量。后续的实验中删除了3个基于域名字符串的特征，达到了更高的准确度。



## 收获



1、ELM和ANN模型是否能达到更好的效果呢？

2、本文考虑到了DNS请求序列中的时间特性，这是大多数方法没有考虑到的。

3、 本文所用的数据集非常大，有173G，第一次见到这么大的数据集。而对于真实的场景，数据集都是非常大的。

4、本文用到的是DNS日志，有时也可以用到DNS的响应信息，响应中有时也包含着部分有用的内容。比如当此方法与恶意域检测方法相结合时，需要响应记录。

5、Canopy算法不需要用户预先指定聚类数目，具有很好的实用价值。它的速度较快，但准确度较低。通常与k-means算法配合使用，用来确定聚类的数目。